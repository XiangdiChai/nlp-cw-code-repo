{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"BERT_and_RoBERTa .ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e9e596b27e124b30beaa8ac6f1c29f22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e93ea01248a1416ea7e80ed53569cdf0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_844ff8f6b68f41938c951027166c156b","IPY_MODEL_64dfb1e094844452979515cb64f090c1"]}},"e93ea01248a1416ea7e80ed53569cdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"844ff8f6b68f41938c951027166c156b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5fe756a9f4174d27b58ae2f61bec5a45","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_123f851b5e0c4272ade69cdeaf1369d7"}},"64dfb1e094844452979515cb64f090c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_65a1dbe071ef46dfbdab099cd57f852f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:35&lt;00:00, 12.1B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80599cd094554309842abed53e7ccdfc"}},"5fe756a9f4174d27b58ae2f61bec5a45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"123f851b5e0c4272ade69cdeaf1369d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65a1dbe071ef46dfbdab099cd57f852f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80599cd094554309842abed53e7ccdfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fc94946a65646e5b98b5a139495d4d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2f923a6c3d05426aa4be5d7f3e88ea59","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8f6009fa8c3c4f4eba1dc56fa318082b","IPY_MODEL_9de2351cf15f48b183be32e3b0e159db"]}},"2f923a6c3d05426aa4be5d7f3e88ea59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f6009fa8c3c4f4eba1dc56fa318082b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f8babd6b4b894d2da94b3d98888dd088","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a7e6017193c464489da46e8ae95642e"}},"9de2351cf15f48b183be32e3b0e159db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a6be861eece0469a8cb3518b9e72432b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:08&lt;00:00, 53.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57fa0bcc99924c508bcd3d152ff0559e"}},"f8babd6b4b894d2da94b3d98888dd088":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3a7e6017193c464489da46e8ae95642e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6be861eece0469a8cb3518b9e72432b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57fa0bcc99924c508bcd3d152ff0559e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cdec4c1b42542a8bfa5c8c2ebe79155":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67a4d16fc8694f1b98dec229c66ebfad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aae0809f8b5f42e0b67388ddeb7fc920","IPY_MODEL_6fc68ed6dd2c4217847b9b5ac720a610"]}},"67a4d16fc8694f1b98dec229c66ebfad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aae0809f8b5f42e0b67388ddeb7fc920":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_857b62c9be424d01bf6ca4a06793d06a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d5d96920ee24d69bccf410937e10511"}},"6fc68ed6dd2c4217847b9b5ac720a610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_910d4801921c42ee933f97b0ba1c7d1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:00&lt;00:00, 702B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01a0a804f85341bb8e192e8e02e31d43"}},"857b62c9be424d01bf6ca4a06793d06a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d5d96920ee24d69bccf410937e10511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"910d4801921c42ee933f97b0ba1c7d1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01a0a804f85341bb8e192e8e02e31d43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fdfbae9cad654cb0a976a4c00be729e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2702d9496ef94ef882385000b545d011","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cfe64e55ee404a86bca79e163fc63b6a","IPY_MODEL_31dcd410c5f942cfaa8d9461586277b9"]}},"2702d9496ef94ef882385000b545d011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfe64e55ee404a86bca79e163fc63b6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1fa704b7506b46a6b16ebcbe6180de3b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df535e9b6ba54d1f94d05da009d3aa43"}},"31dcd410c5f942cfaa8d9461586277b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e5561999abed4cd08e82f82b82e9ed1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:11&lt;00:00, 42.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51d11fad71d34033bf213b161b305485"}},"1fa704b7506b46a6b16ebcbe6180de3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"df535e9b6ba54d1f94d05da009d3aa43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e5561999abed4cd08e82f82b82e9ed1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"51d11fad71d34033bf213b161b305485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d9d0e394a4642fa8a23fc36f1263a1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aceef3ec89254909a0f1e40a74ec8714","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3583a869eaad4b569394fd6c3ee2b33a","IPY_MODEL_89a75c355cfb499ba5c991befe639bb6"]}},"aceef3ec89254909a0f1e40a74ec8714":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3583a869eaad4b569394fd6c3ee2b33a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e4f17dd7531442329ccaadcf87aecfbe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55323a01e0664828a4098e6a7a2ad2f7"}},"89a75c355cfb499ba5c991befe639bb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dfaaa10072774c6dad340f31c81eb6a8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 656kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8d2278c401074fdf985c0426048eb533"}},"e4f17dd7531442329ccaadcf87aecfbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"55323a01e0664828a4098e6a7a2ad2f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfaaa10072774c6dad340f31c81eb6a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8d2278c401074fdf985c0426048eb533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa337f169af24e1aab1ec502ae0ea243":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b1b5bb8be2c24663b898d79f3262a7ab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cc234bdf4554403af71e5ea0e20a6bd","IPY_MODEL_a2e689f949d44855ab26166a9db59fa2"]}},"b1b5bb8be2c24663b898d79f3262a7ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cc234bdf4554403af71e5ea0e20a6bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_32eb9c6fe4bf45ffadf10ba75827bc6c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6ed95a353734490a60f8cfc74838c1f"}},"a2e689f949d44855ab26166a9db59fa2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_518ccfc9e8b849d5b6bea671281bde27","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 1.09MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_222495ff293347adbedb2a3a0602239c"}},"32eb9c6fe4bf45ffadf10ba75827bc6c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b6ed95a353734490a60f8cfc74838c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"518ccfc9e8b849d5b6bea671281bde27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"222495ff293347adbedb2a3a0602239c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f9aec3b471a4712a33f2b5d8744c98b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c0dd8fcb5e054e198b6fddaa48d4bbd9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ec39d48122ff4fe9a92192c630f94ffa","IPY_MODEL_de7b34841f7145dd8d5ccc1785b93b1a"]}},"c0dd8fcb5e054e198b6fddaa48d4bbd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec39d48122ff4fe9a92192c630f94ffa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_982b2a7454b94b2eb405a1a4ccc4fc33","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a42ffe6c8fea44c19e47e7dc3bb10b4f"}},"de7b34841f7145dd8d5ccc1785b93b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2c68720733a4317b2339dae300f4cf7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 1.26MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb40a16432454d9d99ab95929aa82c4a"}},"982b2a7454b94b2eb405a1a4ccc4fc33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a42ffe6c8fea44c19e47e7dc3bb10b4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2c68720733a4317b2339dae300f4cf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb40a16432454d9d99ab95929aa82c4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"sJBrhQAp9dpd"},"source":["### Coursework coding instructions (please also see full coursework spec)\n","\n","Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n","\n","For the task you choose you will need to do two approaches:\n","  - Approach 1, which can use use pre-trained embeddings / models\n","  - Approach 2, which should not use any pre-trained embeddings or models\n","We should be able to run both approaches from the same colab file\n","\n","#### Running your code:\n","  - Your models should run automatically when running your colab file without further intervention\n","  - For each task you should automatically output the performance of both models\n","  - Your code should automatically download any libraries required\n","\n","#### Structure of your code:\n","  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n","  - Otherwise there are no restrictions on what you can do in your code\n","\n","#### Documentation:\n","  - You are expected to produce a .README file summarising how you have approached both tasks\n","\n","#### Reproducibility:\n","  - Your .README file should explain how to replicate the different experiments mentioned in your report\n","\n","Good luck! We are really looking forward to seeing your reports and your model code!"]},{"cell_type":"code","metadata":{"id":"2j8bQt_39dpm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614685948658,"user_tz":0,"elapsed":9342,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"bb075fce-9274-41d1-abbf-76732b0b854e"},"source":["# You will need to download any word embeddings required for your code, e.g.:\n","#!wget http://nlp.stanford.edu/data/glove.6B.zip\n","#!unzip glove.6B.zip\n","\n","# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n","\n","!pip install torch\n","!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 50.8MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 54.7MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=2123569c0360853af55e20eb6cc2f329e771b0064e464fa0f983535a0318a1d0\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"weTOWm1M9dpn","executionInfo":{"status":"ok","timestamp":1614685953016,"user_tz":0,"elapsed":13695,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# Imports packages\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","import pandas as pd\n","import numpy as np\n","import codecs\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"aoLZMFdz9dpn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614685953021,"user_tz":0,"elapsed":13681,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"8549a2b7-a282-43b5-d21e-ec4a6f15e138"},"source":["# Setting random seed and device\n","SEED = 1\n","\n","np.random.seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","cuda_dev = '0'\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","print(f'Using {device}')\n","\n","if use_cuda:\n","    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))     "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using cuda:0\n","GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tVMMI7hJxwFe","executionInfo":{"status":"ok","timestamp":1614686029088,"user_tz":0,"elapsed":755,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# Load data\n","train_df = pd.read_csv('train.csv')\n","val_df = pd.read_csv('dev.csv') \n","test_df = pd.read_csv('test.csv') "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFbfnmdQeeug","executionInfo":{"status":"ok","timestamp":1614686030318,"user_tz":0,"elapsed":817,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# define hyperparameter\n","\n","epochs = 2\n","batch_size = 32\n","learning_rate = 3e-5"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ge2odzpgRqaw","executionInfo":{"status":"ok","timestamp":1614686030993,"user_tz":0,"elapsed":1244,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["### preprocessing data\n","\n","\n","## find the start and end position of the key word in original sentence\n","def find_key_word(original):\n","  start_position = original.find('<')\n","  end_position = original.find('>')\n","  return start_position, end_position\n","\n","## replace the word with the substitution word\n","def replace_key_word(original,edit):\n","  start_position, end_position = find_key_word(original)\n","  result = original.replace(original[start_position : end_position+1],edit)\n","  return result\n","\n","# extract the substitution word\n","def extract_key_word(original):\n","  start_position, end_position = find_key_word(original)\n","  result = original[start_position+1 : end_position-1]\n","  return result\n","\n","# using above functions to produce input\n","def preprocessing(dataset):\n","  dataset['replaced'] = dataset.apply(lambda x: extract_key_word(x['original']), axis = 1)\n","  dataset['context']  = dataset.apply(lambda x : replace_key_word(x['original'],x['edit']), axis = 1)\n","  dataset['add_humour'] = dataset.apply(lambda x:x['context'] + ' [SEP] '+ x['edit'] + ' was humorous',axis=1)\n","\n","# preprocess our training, validation and testing data\n","\n","preprocessing(train_df)\n","preprocessing(val_df)\n","preprocessing(test_df)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"bkJ4SQm19dpo","executionInfo":{"status":"ok","timestamp":1614686030993,"user_tz":0,"elapsed":1069,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# We define our training loop\n","\n","def train(train_loader, model, epochs, val_dataloader, tokenizer, optimizer, scheduler):\n","    \"\"\"\n","    Training loop for the model, which calls on eval to evaluate after each epoch\n","    \"\"\"\n","    print(\"Training model.\")\n","    best_rmse = 1\n","    # begin training\n","    for epoch in range(1, epochs+1):\n","\n","        # store prediction and ture label\n","        pre_array = np.array([])\n","        true_array = np.array([])\n","\n","        # record the progress of our training\n","        counter = 0\n","        model.train()\n","\n","        # for each batch we do\n","        for batch in train_loader:\n","          input_ids, attention_masks = collate_fn(list(batch[0]), tokenizer)\n","          input_ids = input_ids.to(device)\n","          attention_masks = attention_masks.to(device)\n","          labels = batch[1].to(device)\n","          model.zero_grad()  \n","\n","          # obtain output      \n","          outputs = model(input_ids, attention_mask = attention_masks, labels = labels)\n","          \n","          # extract loss and logits(predicitons) from outputs\n","          loss = outputs.loss\n","          logits = outputs.logits\n","\n","          # add predictions and labels to array\n","          logits = logits.detach().cpu().numpy()\n","          labels = labels.cpu().numpy()\n","          pre_array = np.append(pre_array,logits)\n","          true_array = np.append(true_array,labels)\n","\n","          # update model parameters and do optimisation\n","          loss.backward()\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","          optimizer.step()\n","          scheduler.step()\n","\n","          # calculate training rmse\n","          _,mse,rmse = model_performance(logits,labels)\n","          counter += 1\n","          \n","\n","          # report the progress of the training and validation results\n","          if counter % 20 == 0:\n","              val_rmse, avg_val_loss = eval(val_loader, model, tokenizer)\n","              print(f'|Epoch: {epoch} |Batch: {counter} | Total Batch: {len(train_loader)} | Train Loss: {loss:.4f} | Train RMSE: {rmse:.4f} | Val Loss: {avg_val_loss:.4f} | Val RMSE: {val_rmse:.4f} |')\n","              if val_rmse < best_rmse:\n","                best_rmse = val_rmse\n","                torch.save(model.state_dict(), 'best_model.pt')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"aay8Omb4xbuW","executionInfo":{"status":"ok","timestamp":1614686030994,"user_tz":0,"elapsed":929,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# How we print the model performance\n","\n","def model_performance(output, target):\n","    \"\"\"\n","    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n","    \"\"\"\n","    sq_error = (output - target)**2\n","    sse = np.sum(sq_error)\n","    mse = np.mean(sq_error)\n","    rmse = np.sqrt(mse)\n","\n","    return sse, mse, rmse"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWevPvP99dpo","executionInfo":{"status":"ok","timestamp":1614686030995,"user_tz":0,"elapsed":739,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# We evaluate performance on our dev set\n","\n","def eval(val_loader, model, tokenizer):\n","    \"\"\"\n","    Evaluating model performance on the dev set\n","    \"\"\"\n","    # enter evaluation model\n","    model.eval()\n","\n","    # store model prediction and true label\n","    sum_loss = 0\n","    pre_array = np.array([])\n","    true_array = np.array([])\n","\n","    for batch in val_loader:\n","\n","        # tokenize each batch\n","        input_ids, attention_masks = collate_fn(list(batch[0]), tokenizer)\n","        input_ids = input_ids.to(device)\n","        attention_masks = attention_masks.to(device)\n","        labels = batch[1].to(device)\n","\n","        # obtain output\n","        with torch.no_grad():        \n","            outputs = model(input_ids, attention_mask=attention_masks, labels= labels)\n","        \n","        # extract loss from outputs\n","        loss = outputs.loss\n","        sum_loss += loss.item()\n","\n","        # extract logits(predictions) from outputs \n","        logits = outputs.logits\n","        logits = logits.detach().cpu().numpy()\n","        labels = labels.cpu().numpy()\n","\n","        # add predictions and labels to array\n","        pre_array = np.append(pre_array,logits)\n","        true_array = np.append(true_array,labels)\n","\n","     # calculate validation rmse   \n","    _,_,rmse = model_performance(pre_array,true_array)\n","\n","    avg_loss = sum_loss / len(val_loader)\n","\n","    return rmse, avg_loss"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGWzdLNRKQM_","executionInfo":{"status":"ok","timestamp":1614686030995,"user_tz":0,"elapsed":578,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["# We evaluate performance on our test set\n","\n","def test(final_model, test_loader, tokenizer):\n","  '''\n","  Testing model performance on the dev set\n","  '''\n","  # evaluation model\n","  final_model.eval()\n","  pre_array = np.array([])\n","  for batch in test_loader:\n","    # obtain input_id and attention_mask\n","    input_ids, attention_masks = collate_fn(list(batch), tokenizer)\n","\n","    # to device\n","    input_ids = input_ids.to(device)\n","    attention_masks = attention_masks.to(device)\n","\n","    # obtain the output from final_model\n","    with torch.no_grad():        \n","        outputs = final_model(input_ids, attention_mask=attention_masks)\n","    logits = outputs.logits\n","    logits = logits.detach().cpu().numpy()\n","    \n","    # add prediction of each input\n","    pre_array = np.append(pre_array,logits)\n","\n","  return pre_array"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5gTJmRq9dpp","executionInfo":{"status":"ok","timestamp":1614686030996,"user_tz":0,"elapsed":404,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}}},"source":["## get input_id and attention_mask of each batch\n","def collate_fn(batch, tokenizer):\n","  '''\n","  Tokenize our batch\n","  '''\n","  # list stored the input_id and attention_mask\n","  input_ids = []\n","  attention_masks = []\n","\n","  # implement tokenization for each row of a batch\n","  for row in batch:\n","    encodings = tokenizer(row, add_special_tokens = True, max_length = 32, return_tensors = 'pt', truncation=True, padding='max_length')\n","    input_ids.append(encodings['input_ids'])\n","    attention_masks.append(encodings['attention_mask'])\n","\n","  # convert list to tensor\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  return input_ids, attention_masks\n","\n","\n","\n","## change dataframe to readable dataset\n","class Task1Dataset(Dataset):\n","\n","    def __init__(self, df, training = True):\n","\n","\n","        ######################################################################\n","        ############# when train for context   ###############################   \n","        ############# please uncomment the 'self.x_train = df['context']'#####\n","        ############# And comment the 'self.x_train = df['add_humour']'#######\n","        ######################################################################\n","\n","        # self.x_train = df['context']\n","        self.x_train = df['add_humour']\n","\n","        # if we are in the training phrase\n","        self.training = training\n","        if self.training:\n","          # label = y\n","          self.y_train = df['meanGrade']\n","\n","    def __len__(self):\n","        return len(self.x_train)\n","\n","    def __getitem__(self, item):\n","        if self.training:\n","          return self.x_train[item], self.y_train[item]\n","        else:\n","          return self.x_train[item]\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":550,"referenced_widgets":["e9e596b27e124b30beaa8ac6f1c29f22","e93ea01248a1416ea7e80ed53569cdf0","844ff8f6b68f41938c951027166c156b","64dfb1e094844452979515cb64f090c1","5fe756a9f4174d27b58ae2f61bec5a45","123f851b5e0c4272ade69cdeaf1369d7","65a1dbe071ef46dfbdab099cd57f852f","80599cd094554309842abed53e7ccdfc","6fc94946a65646e5b98b5a139495d4d6","2f923a6c3d05426aa4be5d7f3e88ea59","8f6009fa8c3c4f4eba1dc56fa318082b","9de2351cf15f48b183be32e3b0e159db","f8babd6b4b894d2da94b3d98888dd088","3a7e6017193c464489da46e8ae95642e","a6be861eece0469a8cb3518b9e72432b","57fa0bcc99924c508bcd3d152ff0559e","5cdec4c1b42542a8bfa5c8c2ebe79155","67a4d16fc8694f1b98dec229c66ebfad","aae0809f8b5f42e0b67388ddeb7fc920","6fc68ed6dd2c4217847b9b5ac720a610","857b62c9be424d01bf6ca4a06793d06a","5d5d96920ee24d69bccf410937e10511","910d4801921c42ee933f97b0ba1c7d1c","01a0a804f85341bb8e192e8e02e31d43","fdfbae9cad654cb0a976a4c00be729e0","2702d9496ef94ef882385000b545d011","cfe64e55ee404a86bca79e163fc63b6a","31dcd410c5f942cfaa8d9461586277b9","1fa704b7506b46a6b16ebcbe6180de3b","df535e9b6ba54d1f94d05da009d3aa43","e5561999abed4cd08e82f82b82e9ed1e","51d11fad71d34033bf213b161b305485","0d9d0e394a4642fa8a23fc36f1263a1b","aceef3ec89254909a0f1e40a74ec8714","3583a869eaad4b569394fd6c3ee2b33a","89a75c355cfb499ba5c991befe639bb6","e4f17dd7531442329ccaadcf87aecfbe","55323a01e0664828a4098e6a7a2ad2f7","dfaaa10072774c6dad340f31c81eb6a8","8d2278c401074fdf985c0426048eb533","fa337f169af24e1aab1ec502ae0ea243","b1b5bb8be2c24663b898d79f3262a7ab","7cc234bdf4554403af71e5ea0e20a6bd","a2e689f949d44855ab26166a9db59fa2","32eb9c6fe4bf45ffadf10ba75827bc6c","b6ed95a353734490a60f8cfc74838c1f","518ccfc9e8b849d5b6bea671281bde27","222495ff293347adbedb2a3a0602239c","1f9aec3b471a4712a33f2b5d8744c98b","c0dd8fcb5e054e198b6fddaa48d4bbd9","ec39d48122ff4fe9a92192c630f94ffa","de7b34841f7145dd8d5ccc1785b93b1a","982b2a7454b94b2eb405a1a4ccc4fc33","a42ffe6c8fea44c19e47e7dc3bb10b4f","b2c68720733a4317b2339dae300f4cf7","eb40a16432454d9d99ab95929aa82c4a"]},"id":"lRXW0z89m6hj","executionInfo":{"status":"ok","timestamp":1614686069542,"user_tz":0,"elapsed":38784,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"39532d30-edc7-4069-863e-60bf79dd9e35"},"source":["#### define our model\n","\n","## model can be Bert or Roberta\n","\n","## we are doing regression problem only having one label (num_labels = 1)\n","\n","# for bert\n","model_bert = BertForSequenceClassification.from_pretrained('bert-base-uncased',  num_labels = 1)\n","model_bert.cuda()\n","model_bert = model_bert.double()\n","\n","# for roberta\n","model_roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 1)\n","model_roberta.cuda()\n","model_roberta = model_roberta.double()\n","\n","\n","optimizer_bert = AdamW(model_bert.parameters(),lr = learning_rate, eps = 1e-8)\n","optimizer_roberta = AdamW(model_roberta.parameters(),lr = learning_rate, eps = 1e-8)\n","\n","# construct tokenizer for bert and roberta model\n","tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n","tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","\n","# construct dataset and dataloader\n","train_dataset = Task1Dataset(train_df)\n","train_loader = torch.utils.data.DataLoader(train_dataset,  shuffle = True, batch_size = batch_size)\n","val_dataset = Task1Dataset(val_df)\n","val_loader = torch.utils.data.DataLoader(val_dataset,  shuffle = False, batch_size = batch_size)\n","test_dataset = Task1Dataset(test_df,False)\n","test_loader = torch.utils.data.DataLoader(test_dataset, shuffle = False, batch_size = batch_size)\n","\n","# computer total steps\n","total_steps = len(train_loader) * epochs\n","scheduler_bert = get_linear_schedule_with_warmup(optimizer_bert, num_warmup_steps = 0, num_training_steps = total_steps)\n","scheduler_roberta = get_linear_schedule_with_warmup(optimizer_roberta, num_warmup_steps = 0, num_training_steps = total_steps)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9e596b27e124b30beaa8ac6f1c29f22","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fc94946a65646e5b98b5a139495d4d6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5cdec4c1b42542a8bfa5c8c2ebe79155","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdfbae9cad654cb0a976a4c00be729e0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d9d0e394a4642fa8a23fc36f1263a1b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa337f169af24e1aab1ec502ae0ea243","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f9aec3b471a4712a33f2b5d8744c98b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"WUxtiVI49dpq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614689471414,"user_tz":0,"elapsed":3440477,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"c90af3c1-bf79-4aa0-cdd9-26ef99c5a592"},"source":["## Approach 1 code, using functions defined above:\n","# train for roberta\n","train(train_loader, model_roberta, epochs, val_loader, tokenizer_roberta, optimizer_roberta, scheduler_roberta)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Training model.\n","|Epoch: 1 |Batch: 20 | Total Batch: 302 | Train Loss: 0.4684 | Train RMSE: 0.6968 | Val Loss: 0.3824 | Val RMSE: 0.6183 |\n","|Epoch: 1 |Batch: 40 | Total Batch: 302 | Train Loss: 0.3448 | Train RMSE: 0.6280 | Val Loss: 0.3075 | Val RMSE: 0.5542 |\n","|Epoch: 1 |Batch: 60 | Total Batch: 302 | Train Loss: 0.4093 | Train RMSE: 0.7172 | Val Loss: 0.3264 | Val RMSE: 0.5710 |\n","|Epoch: 1 |Batch: 80 | Total Batch: 302 | Train Loss: 0.3322 | Train RMSE: 0.5953 | Val Loss: 0.3150 | Val RMSE: 0.5607 |\n","|Epoch: 1 |Batch: 100 | Total Batch: 302 | Train Loss: 0.4211 | Train RMSE: 0.6633 | Val Loss: 0.3047 | Val RMSE: 0.5517 |\n","|Epoch: 1 |Batch: 120 | Total Batch: 302 | Train Loss: 0.2763 | Train RMSE: 0.5593 | Val Loss: 0.2819 | Val RMSE: 0.5301 |\n","|Epoch: 1 |Batch: 140 | Total Batch: 302 | Train Loss: 0.3593 | Train RMSE: 0.6296 | Val Loss: 0.3150 | Val RMSE: 0.5603 |\n","|Epoch: 1 |Batch: 160 | Total Batch: 302 | Train Loss: 0.2597 | Train RMSE: 0.6062 | Val Loss: 0.2945 | Val RMSE: 0.5423 |\n","|Epoch: 1 |Batch: 180 | Total Batch: 302 | Train Loss: 0.2505 | Train RMSE: 0.6071 | Val Loss: 0.2811 | Val RMSE: 0.5294 |\n","|Epoch: 1 |Batch: 200 | Total Batch: 302 | Train Loss: 0.2280 | Train RMSE: 0.5509 | Val Loss: 0.2805 | Val RMSE: 0.5292 |\n","|Epoch: 1 |Batch: 220 | Total Batch: 302 | Train Loss: 0.2307 | Train RMSE: 0.5734 | Val Loss: 0.2799 | Val RMSE: 0.5286 |\n","|Epoch: 1 |Batch: 240 | Total Batch: 302 | Train Loss: 0.3277 | Train RMSE: 0.6635 | Val Loss: 0.2905 | Val RMSE: 0.5387 |\n","|Epoch: 1 |Batch: 260 | Total Batch: 302 | Train Loss: 0.2105 | Train RMSE: 0.6217 | Val Loss: 0.2818 | Val RMSE: 0.5302 |\n","|Epoch: 1 |Batch: 280 | Total Batch: 302 | Train Loss: 0.2469 | Train RMSE: 0.5974 | Val Loss: 0.2859 | Val RMSE: 0.5339 |\n","|Epoch: 1 |Batch: 300 | Total Batch: 302 | Train Loss: 0.2537 | Train RMSE: 0.5647 | Val Loss: 0.2902 | Val RMSE: 0.5378 |\n","|Epoch: 2 |Batch: 20 | Total Batch: 302 | Train Loss: 0.1909 | Train RMSE: 0.6371 | Val Loss: 0.2937 | Val RMSE: 0.5415 |\n","|Epoch: 2 |Batch: 40 | Total Batch: 302 | Train Loss: 0.1713 | Train RMSE: 0.7392 | Val Loss: 0.2866 | Val RMSE: 0.5350 |\n","|Epoch: 2 |Batch: 60 | Total Batch: 302 | Train Loss: 0.2623 | Train RMSE: 0.7257 | Val Loss: 0.2717 | Val RMSE: 0.5207 |\n","|Epoch: 2 |Batch: 80 | Total Batch: 302 | Train Loss: 0.1748 | Train RMSE: 0.6020 | Val Loss: 0.2672 | Val RMSE: 0.5164 |\n","|Epoch: 2 |Batch: 100 | Total Batch: 302 | Train Loss: 0.2590 | Train RMSE: 0.7902 | Val Loss: 0.2697 | Val RMSE: 0.5187 |\n","|Epoch: 2 |Batch: 120 | Total Batch: 302 | Train Loss: 0.1767 | Train RMSE: 0.6698 | Val Loss: 0.2760 | Val RMSE: 0.5249 |\n","|Epoch: 2 |Batch: 140 | Total Batch: 302 | Train Loss: 0.2489 | Train RMSE: 0.7988 | Val Loss: 0.2732 | Val RMSE: 0.5220 |\n","|Epoch: 2 |Batch: 160 | Total Batch: 302 | Train Loss: 0.3234 | Train RMSE: 0.6095 | Val Loss: 0.2700 | Val RMSE: 0.5190 |\n","|Epoch: 2 |Batch: 180 | Total Batch: 302 | Train Loss: 0.1700 | Train RMSE: 0.6971 | Val Loss: 0.2778 | Val RMSE: 0.5266 |\n","|Epoch: 2 |Batch: 200 | Total Batch: 302 | Train Loss: 0.3214 | Train RMSE: 0.6334 | Val Loss: 0.2708 | Val RMSE: 0.5199 |\n","|Epoch: 2 |Batch: 220 | Total Batch: 302 | Train Loss: 0.1201 | Train RMSE: 0.6008 | Val Loss: 0.2678 | Val RMSE: 0.5169 |\n","|Epoch: 2 |Batch: 240 | Total Batch: 302 | Train Loss: 0.1022 | Train RMSE: 0.6394 | Val Loss: 0.2697 | Val RMSE: 0.5187 |\n","|Epoch: 2 |Batch: 260 | Total Batch: 302 | Train Loss: 0.1829 | Train RMSE: 0.6901 | Val Loss: 0.2691 | Val RMSE: 0.5181 |\n","|Epoch: 2 |Batch: 280 | Total Batch: 302 | Train Loss: 0.1938 | Train RMSE: 0.6277 | Val Loss: 0.2672 | Val RMSE: 0.5163 |\n","|Epoch: 2 |Batch: 300 | Total Batch: 302 | Train Loss: 0.2146 | Train RMSE: 0.6314 | Val Loss: 0.2690 | Val RMSE: 0.5181 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v9MtHYL-Th2d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614689570424,"user_tz":0,"elapsed":79183,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"5ed254ec-997a-42ac-d83f-bff4565d47c7"},"source":["###################### implement model on test data (need test dataset with label)\n","\n","##### need change the name of the test csv\n","true_df = pd.read_csv('test with label.csv') \n","model_roberta.load_state_dict(torch.load('best_model.pt'))\n","prediction_roberta = test(model_roberta, test_loader, tokenizer_roberta)\n","_, _, rmse_test_roberta = model_performance(prediction_roberta, np.array(true_df['meanGrade']))\n","print(rmse_test_roberta)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["0.5161263698122204\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nxFy7FEO6mfy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614693135730,"user_tz":0,"elapsed":3411261,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"68691fef-ad19-45a3-d100-d51d819ce7fe"},"source":["# train for bert\n","train(train_loader, model_bert, epochs, val_loader, tokenizer_bert, optimizer_bert, scheduler_bert)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Training model.\n","|Epoch: 1 |Batch: 20 | Total Batch: 302 | Train Loss: 0.2317 | Train RMSE: 0.4586 | Val Loss: 0.3332 | Val RMSE: 0.5768 |\n","|Epoch: 1 |Batch: 40 | Total Batch: 302 | Train Loss: 0.2675 | Train RMSE: 0.5193 | Val Loss: 0.3144 | Val RMSE: 0.5605 |\n","|Epoch: 1 |Batch: 60 | Total Batch: 302 | Train Loss: 0.6578 | Train RMSE: 0.7937 | Val Loss: 0.3054 | Val RMSE: 0.5524 |\n","|Epoch: 1 |Batch: 80 | Total Batch: 302 | Train Loss: 0.1914 | Train RMSE: 0.5311 | Val Loss: 0.3000 | Val RMSE: 0.5476 |\n","|Epoch: 1 |Batch: 100 | Total Batch: 302 | Train Loss: 0.3711 | Train RMSE: 0.7026 | Val Loss: 0.2932 | Val RMSE: 0.5410 |\n","|Epoch: 1 |Batch: 120 | Total Batch: 302 | Train Loss: 0.3086 | Train RMSE: 0.6337 | Val Loss: 0.2959 | Val RMSE: 0.5436 |\n","|Epoch: 1 |Batch: 140 | Total Batch: 302 | Train Loss: 0.2937 | Train RMSE: 0.6415 | Val Loss: 0.2899 | Val RMSE: 0.5380 |\n","|Epoch: 1 |Batch: 160 | Total Batch: 302 | Train Loss: 0.2845 | Train RMSE: 0.5724 | Val Loss: 0.2911 | Val RMSE: 0.5390 |\n","|Epoch: 1 |Batch: 180 | Total Batch: 302 | Train Loss: 0.3391 | Train RMSE: 0.6251 | Val Loss: 0.2831 | Val RMSE: 0.5314 |\n","|Epoch: 1 |Batch: 200 | Total Batch: 302 | Train Loss: 0.1850 | Train RMSE: 0.5909 | Val Loss: 0.2938 | Val RMSE: 0.5413 |\n","|Epoch: 1 |Batch: 220 | Total Batch: 302 | Train Loss: 0.2485 | Train RMSE: 0.5602 | Val Loss: 0.2869 | Val RMSE: 0.5352 |\n","|Epoch: 1 |Batch: 240 | Total Batch: 302 | Train Loss: 0.2233 | Train RMSE: 0.5908 | Val Loss: 0.2808 | Val RMSE: 0.5293 |\n","|Epoch: 1 |Batch: 260 | Total Batch: 302 | Train Loss: 0.2655 | Train RMSE: 0.5517 | Val Loss: 0.2822 | Val RMSE: 0.5305 |\n","|Epoch: 1 |Batch: 280 | Total Batch: 302 | Train Loss: 0.2532 | Train RMSE: 0.5714 | Val Loss: 0.2850 | Val RMSE: 0.5334 |\n","|Epoch: 1 |Batch: 300 | Total Batch: 302 | Train Loss: 0.3394 | Train RMSE: 0.6609 | Val Loss: 0.2854 | Val RMSE: 0.5338 |\n","|Epoch: 2 |Batch: 20 | Total Batch: 302 | Train Loss: 0.2801 | Train RMSE: 0.7373 | Val Loss: 0.3189 | Val RMSE: 0.5643 |\n","|Epoch: 2 |Batch: 40 | Total Batch: 302 | Train Loss: 0.2341 | Train RMSE: 0.6632 | Val Loss: 0.3121 | Val RMSE: 0.5585 |\n","|Epoch: 2 |Batch: 60 | Total Batch: 302 | Train Loss: 0.1515 | Train RMSE: 0.6724 | Val Loss: 0.2801 | Val RMSE: 0.5288 |\n","|Epoch: 2 |Batch: 80 | Total Batch: 302 | Train Loss: 0.0966 | Train RMSE: 0.6815 | Val Loss: 0.2862 | Val RMSE: 0.5345 |\n","|Epoch: 2 |Batch: 100 | Total Batch: 302 | Train Loss: 0.1643 | Train RMSE: 0.6850 | Val Loss: 0.2809 | Val RMSE: 0.5296 |\n","|Epoch: 2 |Batch: 120 | Total Batch: 302 | Train Loss: 0.2140 | Train RMSE: 0.6836 | Val Loss: 0.2858 | Val RMSE: 0.5342 |\n","|Epoch: 2 |Batch: 140 | Total Batch: 302 | Train Loss: 0.1580 | Train RMSE: 0.8026 | Val Loss: 0.2876 | Val RMSE: 0.5359 |\n","|Epoch: 2 |Batch: 160 | Total Batch: 302 | Train Loss: 0.1841 | Train RMSE: 0.6173 | Val Loss: 0.2821 | Val RMSE: 0.5306 |\n","|Epoch: 2 |Batch: 180 | Total Batch: 302 | Train Loss: 0.1584 | Train RMSE: 0.6474 | Val Loss: 0.2819 | Val RMSE: 0.5304 |\n","|Epoch: 2 |Batch: 200 | Total Batch: 302 | Train Loss: 0.2675 | Train RMSE: 0.6411 | Val Loss: 0.2848 | Val RMSE: 0.5330 |\n","|Epoch: 2 |Batch: 220 | Total Batch: 302 | Train Loss: 0.1399 | Train RMSE: 0.6030 | Val Loss: 0.2809 | Val RMSE: 0.5295 |\n","|Epoch: 2 |Batch: 240 | Total Batch: 302 | Train Loss: 0.1588 | Train RMSE: 0.7258 | Val Loss: 0.2842 | Val RMSE: 0.5326 |\n","|Epoch: 2 |Batch: 260 | Total Batch: 302 | Train Loss: 0.2389 | Train RMSE: 0.8011 | Val Loss: 0.2804 | Val RMSE: 0.5289 |\n","|Epoch: 2 |Batch: 280 | Total Batch: 302 | Train Loss: 0.1520 | Train RMSE: 0.7403 | Val Loss: 0.2799 | Val RMSE: 0.5285 |\n","|Epoch: 2 |Batch: 300 | Total Batch: 302 | Train Loss: 0.2164 | Train RMSE: 0.7825 | Val Loss: 0.2809 | Val RMSE: 0.5294 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W573ItJ-UJAI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614693223137,"user_tz":0,"elapsed":79185,"user":{"displayName":"ming xu","photoUrl":"","userId":"09677624155207564250"}},"outputId":"dc7477f7-a40e-4bcb-a03a-475ab40eea41"},"source":["###################### implement model on test data (need test dataset with label)\n","##### need change the name of the test csv\n","true_df = pd.read_csv('test with label.csv') \n","prediction_bert = test(model_bert, test_loader, tokenizer_bert)\n","_, _, rmse_test_bert = model_performance(prediction_bert, np.array(true_df['meanGrade']))\n","print(rmse_test_bert)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["0.5287467993311363\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tk6i1a07GpnL"},"source":["#### Approach 2: No pre-trained representations"]},{"cell_type":"code","metadata":{"id":"EglvE0XW9dpr"},"source":["train_and_dev = train_df['edit']\n","\n","training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n","                                                                        test_size=(1-train_proportion),\n","                                                                        random_state=42)\n","\n","# We train a Tf-idf model\n","count_vect = CountVectorizer(stop_words='english')\n","train_counts = count_vect.fit_transform(training_data)\n","transformer = TfidfTransformer().fit(train_counts)\n","train_counts = transformer.transform(train_counts)\n","regression_model = LinearRegression().fit(train_counts, training_y)\n","\n","# Train predictions\n","predicted_train = regression_model.predict(train_counts)\n","\n","# Calculate Tf-idf using train and dev, and validate model on dev:\n","test_and_test_counts = count_vect.transform(train_and_dev)\n","transformer = TfidfTransformer().fit(test_and_test_counts)\n","\n","test_counts = count_vect.transform(dev_data)\n","\n","test_counts = transformer.transform(test_counts)\n","\n","# Dev predictions\n","predicted = regression_model.predict(test_counts)\n","\n","# We run the evaluation:\n","print(\"\\nTrain performance:\")\n","sse, mse = model_performance(predicted_train, training_y, True)\n","\n","\n","print(\"\\nDev performance:\")\n","sse, mse = model_performance(predicted, dev_y, True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hG-DyRHs9dps"},"source":["#### Baseline for task 2"]},{"cell_type":"code","metadata":{"id":"b59dUgQo9dps"},"source":["# Baseline for the task\n","pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n","print(\"\\nBaseline performance:\")\n","sse, mse = model_performance(pred_baseline, dev_y, True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6v52Iqz9dpt"},"source":[""],"execution_count":null,"outputs":[]}]}